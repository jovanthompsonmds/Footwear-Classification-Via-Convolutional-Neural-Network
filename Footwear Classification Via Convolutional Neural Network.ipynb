{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a67bdf-c61a-4ada-bc6b-9f0562855754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8fadad2-c683-490d-8c86-25694bcb2379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jovan\\AppData\\Local\\Programs\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6058 - loss: 0.8657 - val_accuracy: 0.8667 - val_loss: 0.3470\n",
      "Epoch 2/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.8918 - loss: 0.2846 - val_accuracy: 0.9111 - val_loss: 0.2436\n",
      "Epoch 3/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.9413 - loss: 0.1751 - val_accuracy: 0.9022 - val_loss: 0.2691\n",
      "Epoch 4/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9546 - loss: 0.1375 - val_accuracy: 0.9156 - val_loss: 0.2278\n",
      "Epoch 5/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.9680 - loss: 0.0928 - val_accuracy: 0.9467 - val_loss: 0.1794\n",
      "Epoch 6/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.9695 - loss: 0.1019 - val_accuracy: 0.9244 - val_loss: 0.2246\n",
      "Epoch 7/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.9790 - loss: 0.0697 - val_accuracy: 0.9467 - val_loss: 0.1499\n",
      "Epoch 8/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.9872 - loss: 0.0417 - val_accuracy: 0.9667 - val_loss: 0.1122\n",
      "Epoch 9/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.9891 - loss: 0.0319 - val_accuracy: 0.9600 - val_loss: 0.1197\n",
      "Epoch 10/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.9960 - loss: 0.0161 - val_accuracy: 0.9533 - val_loss: 0.1695\n",
      "Epoch 11/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.9905 - loss: 0.0228 - val_accuracy: 0.9689 - val_loss: 0.1159\n",
      "Epoch 12/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.9964 - loss: 0.0077 - val_accuracy: 0.9622 - val_loss: 0.1533\n",
      "Epoch 13/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 0.9733 - val_loss: 0.1222\n",
      "Epoch 14/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.9985 - loss: 0.0089 - val_accuracy: 0.9511 - val_loss: 0.1854\n",
      "Epoch 15/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.9999 - loss: 0.0023 - val_accuracy: 0.9689 - val_loss: 0.1339\n",
      "Epoch 16/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9733 - val_loss: 0.1186\n",
      "Epoch 17/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.7999e-04 - val_accuracy: 0.9711 - val_loss: 0.1267\n",
      "Epoch 18/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 1.5375e-04 - val_accuracy: 0.9711 - val_loss: 0.1296\n",
      "Epoch 19/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.5214e-04 - val_accuracy: 0.9711 - val_loss: 0.1319\n",
      "Epoch 20/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 1.0153e-04 - val_accuracy: 0.9711 - val_loss: 0.1348\n",
      "Epoch 21/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.2079e-04 - val_accuracy: 0.9711 - val_loss: 0.1376\n",
      "Epoch 22/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 6.7015e-05 - val_accuracy: 0.9711 - val_loss: 0.1380\n",
      "Epoch 23/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 7.2521e-05 - val_accuracy: 0.9711 - val_loss: 0.1401\n",
      "Epoch 24/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 5.3791e-05 - val_accuracy: 0.9711 - val_loss: 0.1413\n",
      "Epoch 25/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 5.5288e-05 - val_accuracy: 0.9711 - val_loss: 0.1433\n",
      "Epoch 26/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 4.8324e-05 - val_accuracy: 0.9711 - val_loss: 0.1438\n",
      "Epoch 27/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 4.1015e-05 - val_accuracy: 0.9711 - val_loss: 0.1453\n",
      "Epoch 28/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 3.3111e-05 - val_accuracy: 0.9711 - val_loss: 0.1470\n",
      "Epoch 29/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.9687e-05 - val_accuracy: 0.9711 - val_loss: 0.1475\n",
      "Epoch 30/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 4.5046e-05 - val_accuracy: 0.9711 - val_loss: 0.1496\n",
      "Epoch 31/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 3.2639e-05 - val_accuracy: 0.9711 - val_loss: 0.1517\n",
      "Epoch 32/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 2.3107e-05 - val_accuracy: 0.9711 - val_loss: 0.1518\n",
      "Epoch 33/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.5733e-05 - val_accuracy: 0.9711 - val_loss: 0.1521\n",
      "Epoch 34/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 2.6250e-05 - val_accuracy: 0.9711 - val_loss: 0.1538\n",
      "Epoch 35/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 2.3711e-05 - val_accuracy: 0.9711 - val_loss: 0.1548\n",
      "Epoch 36/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.4319e-05 - val_accuracy: 0.9711 - val_loss: 0.1549\n",
      "Epoch 37/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.3219e-05 - val_accuracy: 0.9711 - val_loss: 0.1577\n",
      "Epoch 38/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.0509e-05 - val_accuracy: 0.9711 - val_loss: 0.1587\n",
      "Epoch 39/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.5484e-05 - val_accuracy: 0.9711 - val_loss: 0.1598\n",
      "Epoch 40/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.6611e-05 - val_accuracy: 0.9711 - val_loss: 0.1596\n",
      "Epoch 41/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 2.1658e-05 - val_accuracy: 0.9711 - val_loss: 0.1605\n",
      "Epoch 42/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.0475e-05 - val_accuracy: 0.9711 - val_loss: 0.1615\n",
      "Epoch 43/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.3966e-05 - val_accuracy: 0.9711 - val_loss: 0.1623\n",
      "Epoch 44/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.1610e-05 - val_accuracy: 0.9711 - val_loss: 0.1630\n",
      "Epoch 45/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.3738e-05 - val_accuracy: 0.9711 - val_loss: 0.1642\n",
      "Epoch 46/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.4368e-05 - val_accuracy: 0.9711 - val_loss: 0.1648\n",
      "Epoch 47/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.1795e-05 - val_accuracy: 0.9711 - val_loss: 0.1654\n",
      "Epoch 48/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.1768e-05 - val_accuracy: 0.9711 - val_loss: 0.1668\n",
      "Epoch 49/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 9.9777e-06 - val_accuracy: 0.9711 - val_loss: 0.1670\n",
      "Epoch 50/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 1.0006e-05 - val_accuracy: 0.9711 - val_loss: 0.1679\n",
      "Epoch 51/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 9.9789e-06 - val_accuracy: 0.9711 - val_loss: 0.1687\n",
      "Epoch 52/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 8.7646e-06 - val_accuracy: 0.9711 - val_loss: 0.1698\n",
      "Epoch 53/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 9.9022e-06 - val_accuracy: 0.9711 - val_loss: 0.1703\n",
      "Epoch 54/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 9.1039e-06 - val_accuracy: 0.9711 - val_loss: 0.1707\n",
      "Epoch 55/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 8.2753e-06 - val_accuracy: 0.9711 - val_loss: 0.1717\n",
      "Epoch 56/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 6.8885e-06 - val_accuracy: 0.9711 - val_loss: 0.1722\n",
      "Epoch 57/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.0611e-06 - val_accuracy: 0.9711 - val_loss: 0.1731\n",
      "Epoch 58/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.9967e-06 - val_accuracy: 0.9711 - val_loss: 0.1737\n",
      "Epoch 59/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 7.5093e-06 - val_accuracy: 0.9711 - val_loss: 0.1747\n",
      "Epoch 60/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 7.1917e-06 - val_accuracy: 0.9711 - val_loss: 0.1750\n",
      "Epoch 61/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.3064e-06 - val_accuracy: 0.9711 - val_loss: 0.1756\n",
      "Epoch 62/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 7.5171e-06 - val_accuracy: 0.9711 - val_loss: 0.1762\n",
      "Epoch 63/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 5.1896e-06 - val_accuracy: 0.9711 - val_loss: 0.1771\n",
      "Epoch 64/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 5.6251e-06 - val_accuracy: 0.9711 - val_loss: 0.1781\n",
      "Epoch 65/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 4.3844e-06 - val_accuracy: 0.9711 - val_loss: 0.1789\n",
      "Epoch 66/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.8670e-06 - val_accuracy: 0.9711 - val_loss: 0.1792\n",
      "Epoch 67/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.6812e-06 - val_accuracy: 0.9711 - val_loss: 0.1799\n",
      "Epoch 68/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 4.5922e-06 - val_accuracy: 0.9711 - val_loss: 0.1804\n",
      "Epoch 69/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.8962e-06 - val_accuracy: 0.9711 - val_loss: 0.1810\n",
      "Epoch 70/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 4.1259e-06 - val_accuracy: 0.9711 - val_loss: 0.1822\n",
      "Epoch 71/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.6128e-06 - val_accuracy: 0.9711 - val_loss: 0.1823\n",
      "Epoch 72/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 3.9910e-06 - val_accuracy: 0.9711 - val_loss: 0.1827\n",
      "Epoch 73/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 3.4237e-06 - val_accuracy: 0.9711 - val_loss: 0.1833\n",
      "Epoch 74/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 4.3112e-06 - val_accuracy: 0.9711 - val_loss: 0.1842\n",
      "Epoch 75/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 4.4332e-06 - val_accuracy: 0.9711 - val_loss: 0.1851\n",
      "Epoch 76/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.6686e-06 - val_accuracy: 0.9711 - val_loss: 0.1852\n",
      "Epoch 77/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 3.2446e-06 - val_accuracy: 0.9711 - val_loss: 0.1855\n",
      "Epoch 78/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.1464e-06 - val_accuracy: 0.9711 - val_loss: 0.1869\n",
      "Epoch 79/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 3.0499e-06 - val_accuracy: 0.9711 - val_loss: 0.1875\n",
      "Epoch 80/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.4264e-06 - val_accuracy: 0.9711 - val_loss: 0.1883\n",
      "Epoch 81/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.8632e-06 - val_accuracy: 0.9711 - val_loss: 0.1880\n",
      "Epoch 82/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 2.5723e-06 - val_accuracy: 0.9711 - val_loss: 0.1893\n",
      "Epoch 83/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 2.8292e-06 - val_accuracy: 0.9711 - val_loss: 0.1897\n",
      "Epoch 84/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.4998e-06 - val_accuracy: 0.9711 - val_loss: 0.1899\n",
      "Epoch 85/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.5089e-06 - val_accuracy: 0.9711 - val_loss: 0.1906\n",
      "15/15 - 1s - 41ms/step - accuracy: 0.9711 - loss: 0.1906\n",
      "\n",
      "Test accuracy: 0.9711111187934875\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.9958 - loss: 0.0151 - val_accuracy: 0.9600 - val_loss: 0.2179\n",
      "Epoch 2/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9289 - val_loss: 0.3211\n",
      "Epoch 3/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.9422 - val_loss: 0.3091\n",
      "Epoch 4/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.9842 - loss: 0.0459 - val_accuracy: 0.9267 - val_loss: 0.2772\n",
      "Epoch 5/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.9921 - loss: 0.0190 - val_accuracy: 0.9556 - val_loss: 0.1601\n",
      "Epoch 6/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.9980 - loss: 0.0094 - val_accuracy: 0.9489 - val_loss: 0.2398\n",
      "Epoch 7/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.9975 - loss: 0.0044 - val_accuracy: 0.9689 - val_loss: 0.1225\n",
      "Epoch 8/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.0158e-04 - val_accuracy: 0.9689 - val_loss: 0.1480\n",
      "Epoch 9/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.0663e-04 - val_accuracy: 0.9711 - val_loss: 0.1493\n",
      "Epoch 10/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 5.6413e-05 - val_accuracy: 0.9711 - val_loss: 0.1492\n",
      "Epoch 11/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.2381e-05 - val_accuracy: 0.9711 - val_loss: 0.1479\n",
      "Epoch 12/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.5804e-05 - val_accuracy: 0.9733 - val_loss: 0.1485\n",
      "Epoch 13/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 3.6338e-05 - val_accuracy: 0.9733 - val_loss: 0.1490\n",
      "Epoch 14/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.4586e-05 - val_accuracy: 0.9733 - val_loss: 0.1506\n",
      "Epoch 15/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.4940e-05 - val_accuracy: 0.9733 - val_loss: 0.1514\n",
      "Epoch 16/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.9076e-05 - val_accuracy: 0.9733 - val_loss: 0.1526\n",
      "Epoch 17/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.0877e-05 - val_accuracy: 0.9733 - val_loss: 0.1535\n",
      "Epoch 18/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.7190e-05 - val_accuracy: 0.9733 - val_loss: 0.1547\n",
      "Epoch 19/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.4954e-05 - val_accuracy: 0.9733 - val_loss: 0.1556\n",
      "Epoch 20/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.4758e-05 - val_accuracy: 0.9733 - val_loss: 0.1567\n",
      "Epoch 21/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.6423e-05 - val_accuracy: 0.9733 - val_loss: 0.1580\n",
      "Epoch 22/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 1.0683e-05 - val_accuracy: 0.9733 - val_loss: 0.1588\n",
      "Epoch 23/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 1.3193e-05 - val_accuracy: 0.9733 - val_loss: 0.1600\n",
      "Epoch 24/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.2019e-05 - val_accuracy: 0.9733 - val_loss: 0.1613\n",
      "Epoch 25/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.0932e-05 - val_accuracy: 0.9733 - val_loss: 0.1624\n",
      "Epoch 26/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 9.8168e-06 - val_accuracy: 0.9733 - val_loss: 0.1631\n",
      "Epoch 27/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.0472e-05 - val_accuracy: 0.9733 - val_loss: 0.1642\n",
      "Epoch 28/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.0103e-05 - val_accuracy: 0.9733 - val_loss: 0.1653\n",
      "Epoch 29/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.0710e-05 - val_accuracy: 0.9733 - val_loss: 0.1662\n",
      "Epoch 30/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 7.0425e-06 - val_accuracy: 0.9733 - val_loss: 0.1674\n",
      "Epoch 31/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.8333e-06 - val_accuracy: 0.9733 - val_loss: 0.1672\n",
      "Epoch 32/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 7.4769e-06 - val_accuracy: 0.9733 - val_loss: 0.1683\n",
      "Epoch 33/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.5310e-06 - val_accuracy: 0.9733 - val_loss: 0.1693\n",
      "Epoch 34/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 7.5401e-06 - val_accuracy: 0.9733 - val_loss: 0.1706\n",
      "Epoch 35/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 5.9517e-06 - val_accuracy: 0.9733 - val_loss: 0.1716\n",
      "Epoch 36/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 5.4779e-06 - val_accuracy: 0.9733 - val_loss: 0.1726\n",
      "Epoch 37/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 5.3065e-06 - val_accuracy: 0.9733 - val_loss: 0.1735\n",
      "Epoch 38/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 4.4561e-06 - val_accuracy: 0.9733 - val_loss: 0.1741\n",
      "Epoch 39/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.1900e-06 - val_accuracy: 0.9733 - val_loss: 0.1749\n",
      "Epoch 40/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 6.5346e-06 - val_accuracy: 0.9733 - val_loss: 0.1758\n",
      "Epoch 41/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 3.6962e-06 - val_accuracy: 0.9733 - val_loss: 0.1765\n",
      "Epoch 42/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.2882e-06 - val_accuracy: 0.9733 - val_loss: 0.1773\n",
      "Epoch 43/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.0622e-06 - val_accuracy: 0.9733 - val_loss: 0.1780\n",
      "Epoch 44/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.0371e-06 - val_accuracy: 0.9733 - val_loss: 0.1786\n",
      "Epoch 45/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 5.3077e-06 - val_accuracy: 0.9733 - val_loss: 0.1794\n",
      "Epoch 46/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.0303e-06 - val_accuracy: 0.9733 - val_loss: 0.1804\n",
      "Epoch 47/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.4324e-06 - val_accuracy: 0.9733 - val_loss: 0.1811\n",
      "Epoch 48/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.6019e-06 - val_accuracy: 0.9733 - val_loss: 0.1822\n",
      "Epoch 49/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.7860e-06 - val_accuracy: 0.9733 - val_loss: 0.1827\n",
      "Epoch 50/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.9952e-06 - val_accuracy: 0.9733 - val_loss: 0.1833\n",
      "Epoch 51/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.1677e-06 - val_accuracy: 0.9733 - val_loss: 0.1838\n",
      "Epoch 52/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.1003e-06 - val_accuracy: 0.9733 - val_loss: 0.1847\n",
      "Epoch 53/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.0991e-06 - val_accuracy: 0.9733 - val_loss: 0.1854\n",
      "Epoch 54/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.6843e-06 - val_accuracy: 0.9733 - val_loss: 0.1859\n",
      "Epoch 55/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.3579e-06 - val_accuracy: 0.9733 - val_loss: 0.1867\n",
      "Epoch 56/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.5003e-06 - val_accuracy: 0.9733 - val_loss: 0.1873\n",
      "Epoch 57/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 2.5191e-06 - val_accuracy: 0.9733 - val_loss: 0.1879\n",
      "Epoch 58/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.2497e-06 - val_accuracy: 0.9733 - val_loss: 0.1884\n",
      "Epoch 59/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.9644e-06 - val_accuracy: 0.9733 - val_loss: 0.1894\n",
      "Epoch 60/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.0418e-06 - val_accuracy: 0.9733 - val_loss: 0.1900\n",
      "Epoch 61/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.2991e-06 - val_accuracy: 0.9733 - val_loss: 0.1904\n",
      "Epoch 62/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.6838e-06 - val_accuracy: 0.9733 - val_loss: 0.1907\n",
      "Epoch 63/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.5316e-06 - val_accuracy: 0.9733 - val_loss: 0.1916\n",
      "Epoch 64/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.6066e-06 - val_accuracy: 0.9733 - val_loss: 0.1924\n",
      "Epoch 65/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.9699e-06 - val_accuracy: 0.9733 - val_loss: 0.1930\n",
      "Epoch 66/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.6092e-06 - val_accuracy: 0.9733 - val_loss: 0.1933\n",
      "Epoch 67/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.5073e-06 - val_accuracy: 0.9733 - val_loss: 0.1943\n",
      "Epoch 68/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.2362e-06 - val_accuracy: 0.9733 - val_loss: 0.1946\n",
      "Epoch 69/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.4214e-06 - val_accuracy: 0.9733 - val_loss: 0.1953\n",
      "Epoch 70/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.4565e-06 - val_accuracy: 0.9733 - val_loss: 0.1958\n",
      "Epoch 71/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.1133e-06 - val_accuracy: 0.9733 - val_loss: 0.1964\n",
      "Epoch 72/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.3232e-06 - val_accuracy: 0.9733 - val_loss: 0.1971\n",
      "Epoch 73/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.4642e-06 - val_accuracy: 0.9733 - val_loss: 0.1978\n",
      "Epoch 74/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.1985e-06 - val_accuracy: 0.9733 - val_loss: 0.1983\n",
      "Epoch 75/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.1817e-06 - val_accuracy: 0.9733 - val_loss: 0.1988\n",
      "Epoch 76/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.3349e-06 - val_accuracy: 0.9733 - val_loss: 0.1995\n",
      "Epoch 77/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.3413e-06 - val_accuracy: 0.9733 - val_loss: 0.2002\n",
      "Epoch 78/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 9.6232e-07 - val_accuracy: 0.9733 - val_loss: 0.2008\n",
      "Epoch 79/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 9.5523e-07 - val_accuracy: 0.9733 - val_loss: 0.2013\n",
      "Epoch 80/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 8.1724e-07 - val_accuracy: 0.9733 - val_loss: 0.2023\n",
      "Epoch 81/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.0100e-06 - val_accuracy: 0.9733 - val_loss: 0.2028\n",
      "Epoch 82/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 9.0237e-07 - val_accuracy: 0.9733 - val_loss: 0.2034\n",
      "Epoch 83/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.2053e-06 - val_accuracy: 0.9733 - val_loss: 0.2044\n",
      "Epoch 84/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 7.9266e-07 - val_accuracy: 0.9733 - val_loss: 0.2047\n",
      "Epoch 85/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 7.7973e-07 - val_accuracy: 0.9733 - val_loss: 0.2052\n",
      "15/15 - 0s - 23ms/step - accuracy: 0.9733 - loss: 0.2052\n",
      "\n",
      "Test accuracy with adam: 0.9733333587646484\n",
      "Epoch 1/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 7.9049e-07 - val_accuracy: 0.9733 - val_loss: 0.2052\n",
      "Epoch 2/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 6.0071e-07 - val_accuracy: 0.9733 - val_loss: 0.2052\n",
      "Epoch 3/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.9521e-07 - val_accuracy: 0.9733 - val_loss: 0.2052\n",
      "Epoch 4/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.9575e-07 - val_accuracy: 0.9733 - val_loss: 0.2052\n",
      "Epoch 5/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.8975e-07 - val_accuracy: 0.9733 - val_loss: 0.2052\n",
      "Epoch 6/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.8674e-07 - val_accuracy: 0.9733 - val_loss: 0.2052\n",
      "Epoch 7/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.6089e-07 - val_accuracy: 0.9733 - val_loss: 0.2052\n",
      "Epoch 8/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 8.2819e-07 - val_accuracy: 0.9733 - val_loss: 0.2052\n",
      "Epoch 9/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 8.7119e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 10/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 8.7783e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 11/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 7.8911e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 12/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 8.4943e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 13/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 6.7992e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 14/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 6.8201e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 15/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 8.9081e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 16/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 9.8357e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 17/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 8.0096e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 18/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 7.2004e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 19/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 7.1517e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 20/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.8635e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 21/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 9.6367e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 22/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 6.6116e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 23/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 9.8979e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 24/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 6.7152e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 25/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 9.1195e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 26/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 8.9189e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 27/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.0138e-06 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 28/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.3557e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 29/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 7.8775e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 30/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 9.9486e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 31/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 8.9631e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 32/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 8.4161e-07 - val_accuracy: 0.9733 - val_loss: 0.2053\n",
      "Epoch 33/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 9.4910e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 34/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 8.6268e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 35/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 8.4193e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 36/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 8.8113e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 37/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.0283e-06 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 38/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 9.2326e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 39/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 8.3361e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 40/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.7775e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 41/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 8.3947e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 42/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.9313e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 43/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 8.9300e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 44/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 7.8742e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 45/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 9.8110e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 46/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.3142e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 47/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 7.3498e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 48/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 6.3122e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 49/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 5.8806e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 50/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 8.0917e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 51/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 8.6190e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 52/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 7.4132e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 53/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 9.8652e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 54/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.5099e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 55/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 8.0055e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 56/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 7.8106e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 57/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.0697e-06 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 58/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 8.4298e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 59/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 8.3323e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 60/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 8.5018e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 61/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.3752e-07 - val_accuracy: 0.9733 - val_loss: 0.2054\n",
      "Epoch 62/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.1234e-06 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 63/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 7.0726e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 64/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 7.4255e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 65/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 9.0647e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 66/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 6.4243e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 67/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 8.6241e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 68/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 8.3072e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 69/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 8.2479e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 70/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 7.9579e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 71/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 7.5030e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 72/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 7.3532e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 73/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 7.6453e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 74/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 9.2810e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 75/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 7.9555e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 76/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 6.4447e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 77/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 7.9789e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 78/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 8.1260e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 79/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 7.3691e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 80/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 9.4957e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 81/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 7.6502e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 82/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 5.6319e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 83/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 7.6383e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 84/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 9.4640e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "Epoch 85/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.8986e-07 - val_accuracy: 0.9733 - val_loss: 0.2055\n",
      "15/15 - 0s - 31ms/step - accuracy: 0.9733 - loss: 0.2055\n",
      "\n",
      "Test accuracy with sgd: 0.9733333587646484\n",
      "Epoch 1/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.0274e-06 - val_accuracy: 0.9733 - val_loss: 0.2083\n",
      "Epoch 2/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 6.6476e-07 - val_accuracy: 0.9733 - val_loss: 0.2068\n",
      "Epoch 3/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.2620e-07 - val_accuracy: 0.9733 - val_loss: 0.2080\n",
      "Epoch 4/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 6.5857e-07 - val_accuracy: 0.9733 - val_loss: 0.2103\n",
      "Epoch 5/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 6.1930e-07 - val_accuracy: 0.9733 - val_loss: 0.2092\n",
      "Epoch 6/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 6.1656e-07 - val_accuracy: 0.9733 - val_loss: 0.2112\n",
      "Epoch 7/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.7107e-07 - val_accuracy: 0.9733 - val_loss: 0.2125\n",
      "Epoch 8/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 5.9951e-07 - val_accuracy: 0.9733 - val_loss: 0.2133\n",
      "Epoch 9/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.2589e-07 - val_accuracy: 0.9733 - val_loss: 0.2131\n",
      "Epoch 10/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.1508e-07 - val_accuracy: 0.9733 - val_loss: 0.2137\n",
      "Epoch 11/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 5.2169e-07 - val_accuracy: 0.9733 - val_loss: 0.2143\n",
      "Epoch 12/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.7281e-07 - val_accuracy: 0.9733 - val_loss: 0.2148\n",
      "Epoch 13/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 4.2496e-07 - val_accuracy: 0.9733 - val_loss: 0.2157\n",
      "Epoch 14/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.4483e-07 - val_accuracy: 0.9733 - val_loss: 0.2162\n",
      "Epoch 15/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.3714e-07 - val_accuracy: 0.9733 - val_loss: 0.2168\n",
      "Epoch 16/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.7103e-07 - val_accuracy: 0.9733 - val_loss: 0.2173\n",
      "Epoch 17/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.8787e-07 - val_accuracy: 0.9733 - val_loss: 0.2164\n",
      "Epoch 18/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.9714e-07 - val_accuracy: 0.9733 - val_loss: 0.2188\n",
      "Epoch 19/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.3735e-07 - val_accuracy: 0.9733 - val_loss: 0.2190\n",
      "Epoch 20/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.2640e-07 - val_accuracy: 0.9733 - val_loss: 0.2195\n",
      "Epoch 21/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.0336e-07 - val_accuracy: 0.9733 - val_loss: 0.2199\n",
      "Epoch 22/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.3744e-07 - val_accuracy: 0.9733 - val_loss: 0.2200\n",
      "Epoch 23/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.0984e-07 - val_accuracy: 0.9733 - val_loss: 0.2207\n",
      "Epoch 24/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.9610e-07 - val_accuracy: 0.9733 - val_loss: 0.2211\n",
      "Epoch 25/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.7246e-07 - val_accuracy: 0.9733 - val_loss: 0.2215\n",
      "Epoch 26/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.4971e-07 - val_accuracy: 0.9733 - val_loss: 0.2219\n",
      "Epoch 27/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.8355e-07 - val_accuracy: 0.9733 - val_loss: 0.2218\n",
      "Epoch 28/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.1319e-07 - val_accuracy: 0.9733 - val_loss: 0.2223\n",
      "Epoch 29/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.9528e-07 - val_accuracy: 0.9733 - val_loss: 0.2231\n",
      "Epoch 30/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.2172e-07 - val_accuracy: 0.9733 - val_loss: 0.2228\n",
      "Epoch 31/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.5113e-07 - val_accuracy: 0.9733 - val_loss: 0.2235\n",
      "Epoch 32/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.7644e-07 - val_accuracy: 0.9733 - val_loss: 0.2242\n",
      "Epoch 33/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.9145e-07 - val_accuracy: 0.9733 - val_loss: 0.2244\n",
      "Epoch 34/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.3610e-07 - val_accuracy: 0.9733 - val_loss: 0.2246\n",
      "Epoch 35/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.5970e-07 - val_accuracy: 0.9733 - val_loss: 0.2251\n",
      "Epoch 36/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.5505e-07 - val_accuracy: 0.9733 - val_loss: 0.2252\n",
      "Epoch 37/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.6344e-07 - val_accuracy: 0.9733 - val_loss: 0.2257\n",
      "Epoch 38/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.1747e-07 - val_accuracy: 0.9733 - val_loss: 0.2260\n",
      "Epoch 39/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.3550e-07 - val_accuracy: 0.9733 - val_loss: 0.2267\n",
      "Epoch 40/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.2234e-07 - val_accuracy: 0.9733 - val_loss: 0.2264\n",
      "Epoch 41/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.8737e-07 - val_accuracy: 0.9733 - val_loss: 0.2267\n",
      "Epoch 42/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.8958e-07 - val_accuracy: 0.9733 - val_loss: 0.2268\n",
      "Epoch 43/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.5610e-07 - val_accuracy: 0.9733 - val_loss: 0.2257\n",
      "Epoch 44/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.2962e-07 - val_accuracy: 0.9733 - val_loss: 0.2272\n",
      "Epoch 45/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.1066e-07 - val_accuracy: 0.9733 - val_loss: 0.2277\n",
      "Epoch 46/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.9963e-07 - val_accuracy: 0.9733 - val_loss: 0.2279\n",
      "Epoch 47/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.5273e-07 - val_accuracy: 0.9733 - val_loss: 0.2285\n",
      "Epoch 48/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.9653e-07 - val_accuracy: 0.9733 - val_loss: 0.2286\n",
      "Epoch 49/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.7281e-07 - val_accuracy: 0.9733 - val_loss: 0.2287\n",
      "Epoch 50/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.7880e-07 - val_accuracy: 0.9733 - val_loss: 0.2290\n",
      "Epoch 51/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.5687e-07 - val_accuracy: 0.9733 - val_loss: 0.2292\n",
      "Epoch 52/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.9146e-07 - val_accuracy: 0.9733 - val_loss: 0.2294\n",
      "Epoch 53/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.8103e-07 - val_accuracy: 0.9733 - val_loss: 0.2299\n",
      "Epoch 54/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.8943e-07 - val_accuracy: 0.9733 - val_loss: 0.2301\n",
      "Epoch 55/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.6568e-07 - val_accuracy: 0.9733 - val_loss: 0.2303\n",
      "Epoch 56/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.6430e-07 - val_accuracy: 0.9733 - val_loss: 0.2307\n",
      "Epoch 57/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.5006e-07 - val_accuracy: 0.9733 - val_loss: 0.2304\n",
      "Epoch 58/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.7184e-07 - val_accuracy: 0.9733 - val_loss: 0.2307\n",
      "Epoch 59/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.5585e-07 - val_accuracy: 0.9733 - val_loss: 0.2313\n",
      "Epoch 60/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.6952e-07 - val_accuracy: 0.9733 - val_loss: 0.2310\n",
      "Epoch 61/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.9092e-07 - val_accuracy: 0.9733 - val_loss: 0.2316\n",
      "Epoch 62/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.3666e-07 - val_accuracy: 0.9733 - val_loss: 0.2318\n",
      "Epoch 63/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.7187e-07 - val_accuracy: 0.9733 - val_loss: 0.2319\n",
      "Epoch 64/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.4576e-07 - val_accuracy: 0.9733 - val_loss: 0.2322\n",
      "Epoch 65/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.8483e-07 - val_accuracy: 0.9733 - val_loss: 0.2327\n",
      "Epoch 66/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.5168e-07 - val_accuracy: 0.9733 - val_loss: 0.2327\n",
      "Epoch 67/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.2287e-07 - val_accuracy: 0.9733 - val_loss: 0.2330\n",
      "Epoch 68/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.4753e-07 - val_accuracy: 0.9733 - val_loss: 0.2327\n",
      "Epoch 69/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.5847e-07 - val_accuracy: 0.9733 - val_loss: 0.2331\n",
      "Epoch 70/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.1462e-07 - val_accuracy: 0.9733 - val_loss: 0.2330\n",
      "Epoch 71/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.4457e-07 - val_accuracy: 0.9733 - val_loss: 0.2334\n",
      "Epoch 72/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.4448e-07 - val_accuracy: 0.9733 - val_loss: 0.2335\n",
      "Epoch 73/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.5260e-07 - val_accuracy: 0.9733 - val_loss: 0.2338\n",
      "Epoch 74/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.2607e-07 - val_accuracy: 0.9733 - val_loss: 0.2338\n",
      "Epoch 75/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.3945e-07 - val_accuracy: 0.9733 - val_loss: 0.2340\n",
      "Epoch 76/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.4827e-07 - val_accuracy: 0.9733 - val_loss: 0.2341\n",
      "Epoch 77/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.7942e-07 - val_accuracy: 0.9733 - val_loss: 0.2344\n",
      "Epoch 78/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.1470e-07 - val_accuracy: 0.9733 - val_loss: 0.2348\n",
      "Epoch 79/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.1752e-07 - val_accuracy: 0.9733 - val_loss: 0.2351\n",
      "Epoch 80/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.2002e-07 - val_accuracy: 0.9733 - val_loss: 0.2352\n",
      "Epoch 81/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.3313e-07 - val_accuracy: 0.9733 - val_loss: 0.2356\n",
      "Epoch 82/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.2559e-07 - val_accuracy: 0.9733 - val_loss: 0.2355\n",
      "Epoch 83/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.0874e-07 - val_accuracy: 0.9733 - val_loss: 0.2357\n",
      "Epoch 84/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.5055e-07 - val_accuracy: 0.9733 - val_loss: 0.2357\n",
      "Epoch 85/85\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.4808e-07 - val_accuracy: 0.9733 - val_loss: 0.2358\n",
      "15/15 - 0s - 25ms/step - accuracy: 0.9733 - loss: 0.2358\n",
      "\n",
      "Test accuracy with rmsprop: 0.9733333587646484\n"
     ]
    }
   ],
   "source": [
    "# Function to load and preprocess images\n",
    "\n",
    "def load_images_from_folder(folder):  # Takes a folder name as input and loads all images and their labels from that folder to store\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):  # Lists all files in the specified folder\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (102, 136))  # Resize to ensure all images have the same shape\n",
    "            images.append(img)\n",
    "            if folder == 'Boot':\n",
    "                labels.append(0)\n",
    "            elif folder == 'Sandal':\n",
    "                labels.append(1)\n",
    "            elif folder == 'Shoe':\n",
    "                labels.append(2)\n",
    "    return images, labels  # Returns the lists of images and labels\n",
    "\n",
    "# Load images and labels from the respective folders\n",
    "boot_images, boot_labels = load_images_from_folder('Boot')\n",
    "sandal_images, sandal_labels = load_images_from_folder('Sandal')\n",
    "shoe_images, shoe_labels = load_images_from_folder('Shoe')\n",
    "\n",
    "# Concatenate the images and labels from the three categories into single lists\n",
    "images = boot_images + sandal_images + shoe_images\n",
    "labels = boot_labels + sandal_labels + shoe_labels\n",
    "\n",
    "# Convert into NumPy arrays for efficiency & required for numerical input to the neural network\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split dataset into training and testing sets with random state set for consistency in results\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1 b dividing by 255, which is a common preprocessing step for image data\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Initialize the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the first convolutional layer, 2D convolutional layer with 32 filters, a kernel size of 3x3, \n",
    "#'same' padding, ReLU activation, and an input shape matching the dimensions of the images (136x102 pixels, 3 color channels)\n",
    "model.add(layers.Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(136, 102, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add 3 additional convolutional and pooling layers via linear increase of the filters 16, 32, 48 ,and 64 features\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(48, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the data to a 1D array\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add dense fully connected and output layer\n",
    "model.add(layers.Dense(64, activation='relu'))  #  Fully connected layer    \n",
    "model.add(layers.Dense(3, activation='softmax'))  # Match the number of classes in the classification task\n",
    "\n",
    "# Compile the model with the 3 parameters specified\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=85, \n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')\n",
    "\n",
    "# Plot the loss and accuracy graphs\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss over Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Compare optimizers (example with two other optimizers)\n",
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "for opt in optimizers:\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(train_images, train_labels, epochs=85, \n",
    "                        validation_data=(test_images, test_labels))\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "    print(f'\\nTest accuracy with {opt}: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76bd0ad1-9662-414e-92e6-248030dde303",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpretations ='''\n",
    "\n",
    "1. Browse the Kaggle \"Datasets,\" located in the topic Resources.\n",
    "Competed: Filtered and looked over many datasets to make a selection appropriate for the CNN model via the assignment details. \n",
    "\n",
    "2. Select one dataset for your project.\n",
    "Completed: The dataset \"Shoe vs Sandal vs Boot Image Dataset (15K Images)\" was selected from Kaggle at the link below and in the references\n",
    "https://www.kaggle.com/datasets/hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images\n",
    "\n",
    "3. Write a short description of the dataset and what your CNN will recognize.\n",
    "Dataset Description:\n",
    "This Shoe vs Sandal vs Boot Image Dataset contains 15,000 images of shoes, sandals, and boots. There are 5,000 images for each category. \n",
    "The images have a resolution of 136x102 pixels in RGB color model. While this dataset contained 15,000 images, only 2250 were used for the\n",
    "model (750 for each of the 3 categories) because it was seen that this number of images was sufficient to highly train the model to be \n",
    "accurate while also adhering to computational efficiency. Striking this balance was critical because using the entire dataset would have \n",
    "likely resulted in a training time of over 3 hours! Using the reduced dataset kept the training under 30 minutes. \n",
    "\n",
    "Problem Statement:\n",
    "The primary goal of this project is to design, build, and train a Convolutional Neural Network (CNN) to effectively classify images of shoes, \n",
    "sandals, and boots. The dataset used for this task consists of 15,000 images, evenly distributed across three categories: 5,000 images of \n",
    "shoes, 5,000 images of sandals, and 5,000 images of boots. Each image has a resolution of 136x102 pixels and is represented in the RGB color model.\n",
    "\n",
    "The objective of this project extends beyond simply training a CNN; it aims to achieve as close to 100% accuracy as possible in classifying \n",
    "the footwear images. This high level of accuracy is crucial for validating the model's effectiveness and ensuring its reliability in practical \n",
    "applications. The process involves several critical steps: selecting an appropriate dataset, preprocessing the data, building the CNN architecture, \n",
    "training the model, and evaluating its performance.\n",
    "\n",
    "The specific objectives of this assignment and what the CNN will recognize include:\n",
    "\n",
    "- Data Preprocessing: Implement necessary preprocessing steps to prepare the dataset for training, including resizing images, normalizing pixel \n",
    "  values, and splitting the data into training and testing sets.\n",
    "- CNN Initialization and Configuration: Initialize a CNN model and configure its architecture by adding convolutional layers, pooling layers, and \n",
    "  fully connected layers. Each layer's parameters (filters, kernel size, padding, activation functions, etc.) should be carefully chosen to optimize \n",
    "  the model's performance.\n",
    "- Training the Model: Train the CNN using the prepared dataset, ensuring to monitor the model's performance and adjust training parameters such as \n",
    "  epochs and batch size to improve accuracy.\n",
    "- Performance Evaluation: Evaluate the trained model on the test dataset, analyzing its accuracy and loss metrics. Additionally, compare different \n",
    "  optimizers (e.g., Adam, SGD, RMSprop) to identify which one provides the best performance.\n",
    "- Documentation and Reporting: Write a comprehensive technical report detailing the problem statement, solution algorithm, analysis of findings, \n",
    "  and references including all code, comments, outputs, plots, and a thorough discussion of the model's ability to classify images accurately.\n",
    "\n",
    "By following these steps, the project aims to develop a robust CNN model capable of distinguishing between shoes, sandals, and boots with high \n",
    "precision, demonstrating the practical utility of deep learning in image classification tasks.\n",
    "\n",
    "4. Import the appropriate libraries: tensorflow, keras, numpy, glob, matplotlib, MaxPooling2D, and any others that would fit your model.\n",
    "Completed: Imported via the Jupyter notebook as a precursor to executing the code for the training model. Also, prior to initializing the training\n",
    "model, the data was split 80/20 train/test and the pixels for all images were normalized to between 0 and 1 by dividing by 255 given that digital \n",
    "images typically have pixel values ranging from 0 to 255 for each of the RGB color channels. the \n",
    "\n",
    "5. Initialize the CNN.\n",
    "The CNN model was initialized using the Sequential model from Keras because is a simple and convenient way to build neural networks layer by layer\n",
    "in a linear order and helps with visualizing the architecture of the CNN. Also, CNNs typically have a straightforward, sequential structure where \n",
    "each layer’s output is the next layer’s input, so the Sequential model works well for this workflow.\n",
    "\n",
    "6. Utilize the following arguments to add a convolutional layer: Filters, Kernel_size, Padding, Activation Function – Relu, and Input shape.\n",
    "Completed: Added the first convolutional layer with settings, 2D convolutional layer, 16 filters, a kernel size of 3x3, #'same' padding, \n",
    "ReLU activation, and an input shape matching the dimensions of the images (136x102 pixels, 3 color channels). A 2D layer was used because \n",
    "the input data consists of images, which are inherently 2-dimensional (height and width). The number of filters (also called kernels) in each \n",
    "convolutional layer determines the number of features the layer can extract from the input image, where more filters allow the layer to \n",
    "capture more complex and varied features but with higher computational cost. The kernel size 3x3 was chosen because it's one of the most \n",
    "common choices striking a good balance between capturing fine details and maintaining computational efficiency as compared to a 2x2 or 4x4. \n",
    "Padding refers to adding extra pixels around the input image to control the spatial dimensions of the output. Setting padding to 'same' \n",
    "ensures that the output feature map has the same spatial dimensions as the input. The ReLU activation function introduces non-linearity to \n",
    "the model. The input shape specifies the shape of the input image (136x102 pixels with 3 color channels) which is important for training\n",
    "of the model with consistent image sizes; subsequent layers do not need the input shape specified because Keras infers it automatically. \n",
    "\n",
    "7. Down sample the images by applying a pooling operation.\n",
    "Completed: Added a max pooling layer with a pool size of 2x2, which reduces the spatial dimensions of the output by a factor of 2 compared to the\n",
    "4x4 default size. This technique used in CNNs to reduce the spatial dimensions (width and height) of the input volume, thereby reducing the \n",
    "computational complexity and the number of parameters in the network leading to faster training, reduced memory usage, and other benefits.\n",
    "\n",
    "8. Did you choose max pooling, average pooling, or global pooling? Explain which type of pooling you used and why. What are the advantages and \n",
    "disadvantages of your pooling choice?\n",
    "Completed: Max pooling was chosen because it is one of the most commonly used pooling methods in CNNs due to its simplicity and effectiveness in \n",
    "down-sampling feature maps. For this particular assignment and task at hand, max pooling was most appropriate because it preserves the most \n",
    "prominent features of an image by selecting the maximum value (pixel) in each pooling window, which helps in retaining important details and edges \n",
    "in the image that are crucial for object recognition and classification tasks. This method is also good for reducing the image size and giving\n",
    "the property of translation invariance, which is the ability to recognize an object even if it is translated (moved) to different positions \n",
    "within the image; this is critical for the robustness of image recognition and classification. Average pooling takes the average of all values \n",
    "in each pooling window and is beneficial in scenarios where the overall structure is more important than the presence of sharp features, but \n",
    "loses important details and edges which is detrimental to recognition and classification tasks. Global pooling takes the maximum or average \n",
    "value over the entire spatial dimensions of the feature map, reducing the feature map to a single value per feature map. This can result in a \n",
    "significant loss of important features and context making it not optimal for the image recognition and classification task being done here. \n",
    "\n",
    "9. Repeat steps 5–7 to add 3 more convolutional layers.\n",
    "Completed: Three additional convolution layers were added via linear increase of the filters 16 (in layer 1), 32, 48 ,and 64 filters. This\n",
    "created a total of four convolution layers all with the same settings as the first layer as described above. \n",
    "\n",
    "10. Convert the dataset into a 1-D array for input into the next layer (flattening the dataset), which is fully linked.\n",
    "Completed: Code added to flatten to a 1D array that is fully linked.\n",
    "\n",
    "11. Use the dense class to create a fully connected layer (relu activation) and output one (softmax activation).\n",
    "Completed: Code added to create a dense fully connected relu activation layer with 64 filters, and a fully connected output layer with 3\n",
    "filters, to match the number of classes, with softmax activation for classification.\n",
    "\n",
    "12. Train, then appraise the CNN you just created. Compile the CNN model using compile, with three parameters:\n",
    "- Loss Function: use categorical_crossentropy\n",
    "- Optimizer: your choice (Adam, Momentum, Nesterov Accelerated Gradient, or Min-Batch Gradient Descent).\n",
    "- Metrics Arguments: Accuracy to evaluate performance. Fit the model on the training set with at least 85 iterations (epochs). Evaluate the \n",
    "  result. Compare the accuracy and loss function for both the training and test dataset. Plot the loss graph. Plot the accuracy graph.\n",
    "Completed: Code added to compile and train the model with set parameters and outputs for the specified loss function, optimizer, and metrics. \n",
    "\n",
    "13. Discuss how the CNN model is utilized in recognizing the images from the dataset and which optimizer provides for the performance model \n",
    "(highest accuracy and how many times to get to that level) the overall performance of your model. Justify your choice of optimizer by \n",
    "comparing it to two other optimizers.\n",
    "\n",
    "This CNN model is trained on the dataset over multiple epochs, where each epoch represents one complete pass through the training data. During \n",
    "training, the model learns to minimize the loss function, which measures the difference between the predicted and actual labels. Given a large \n",
    "enough training dataset and epochs run, the accuracy can reach near to 100% as is the desired performance. Comparing three different optimizers\n",
    "for Adam, SGD, and RMSprop:the, the results are explained below:\n",
    "\n",
    "Adam Optimizer (2nd comparison run)\n",
    "Performance: Achieved a final test accuracy of 97.33%.\n",
    "Epoch 1: Accuracy: 99.58%, Val_accuracy: 96.00%, Loss: 0.0151, Val_loss: 0.2179\n",
    "Epoch 7: Accuracy: 99.75%, Val_accuracy: 96.89%, Loss: 0.0044, Val_loss: 0.1225\n",
    "Stabilized at 97.33% validation accuracy from epoch 12 onwards.\n",
    "\n",
    "SGD Optimizer\n",
    "Performance: Achieved a final test accuracy of 97.33% but showed slower convergence compared to Adam.\n",
    "Epoch 1: Accuracy: 100.00%, Val_accuracy: 97.33%, Loss: 0.00079, Val_loss: 0.2052\n",
    "Stabilized at 97.33% validation accuracy from epoch the outset onwards.\n",
    "Consistent performance but higher validation loss values 0.2055 compared to Adam 0.2052 and at the end of the training.\n",
    "\n",
    "RMSprop Optimizer\n",
    "Performance: Achieved a final test accuracy of 97.33%, similar to Adam and SGD, but with slightly different loss dynamics.\n",
    "Epoch 1: Accuracy: 100.00%, Val_accuracy: 97.33%\n",
    "Consistent performance similar to Adam and SGD.\n",
    "Val_loss values were higher than those of Adam and SDG and finished at 0.2358.\n",
    "\n",
    "Conclusion\n",
    "Based on the analysis of training performance, convergence speed, and final validation loss, the Adam optimizer is the optimal choice for \n",
    "this CNN model. It provides fast convergence, achieves high accuracy quickly, and maintains a lower validation loss, which is crucial for \n",
    "effective and efficient model training. While SGD and RMSprop also achieve similar final accuracy, Adam's ability to stabilize quickly \n",
    "and minimize loss more effectively makes it the preferred optimizer for this application.\n",
    "\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03bf282c-ef39-4a98-a67e-a41728514483",
   "metadata": {},
   "outputs": [],
   "source": [
    "References ='''\n",
    "\n",
    "References:\n",
    "\n",
    "Aggarwal, C. (2018). Neural networks and deep learning. Springer. ISBN-13: 9783319944623\n",
    "\n",
    "Chollet, F. (2018, January 25). Building Powerful Image Classification Models Using Very Little Data. \n",
    "Retrieved from https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "Brownlee, J. (2019, August 14). How to Configure Image Data Augmentation in Keras. \n",
    "Retrieved from https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "\n",
    "O'Shea, K., & Nash, R. (2015). An Introduction to Convolutional Neural Networks. arXiv preprint arXiv:1511.08458. https://arxiv.org/abs/1511.08458\n",
    "\n",
    "Muzdadid, H. A. (2022). Shoe vs Sandal vs Boot Image Dataset (15K Images). Retrieved from \n",
    "Kaggle. https://www.kaggle.com/datasets/hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images\n",
    "\n",
    "Stack Overflow. (n.d.). Retrieved January, 2024, from https://stackoverflow.com/\n",
    "\n",
    "Reddit. (n.d.). Retrieved January, 2024, from https://www.reddit.com/\n",
    "\n",
    "GitHub. (n.d.). Retrieved January, 2024, from https://www.github.com/\n",
    "\n",
    "Towards Data Science. (n.d.). Retrieved January, 2024, from https://towardsdatascience.com/\n",
    "\n",
    "DataCamp Community. (n.d.). Retrieved January, 2024, from https://www.datacamp.com/community\n",
    "\n",
    "Scikit-learn. (n.d.). Support vector machines. Retrieved from https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
